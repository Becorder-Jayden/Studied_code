# 3. 컨테이너를 다루는 표준 아키텍처, 쿠버네티스

# 쿠버네티스 이해하기

## 쿠버네티스 구성 방법

### 3가지 방법

1. 퍼블릭 클라우드 업체에서 제공하는 **관리형 쿠버네티스**
   - EKS(Amazon Elastic Kubernetes Service) / AKS(Azure Kubernetes Services), GKE(Google Kubernetes Engine) 사용
   - 구성이 이미 다 갖춰져있고, 마스터 노드를 클라우드 업체에서 관리 → 학습용으로 적합하지 않음
2. 플랫폼에서 제공하는 **설치형 쿠버네티스**
   - 수세의 Rancher, 레드햇의 OpenShift 등
   - 유료라서 쉽게 접근하기 어렵다
3. **구성형 쿠버네티스** : 사용하는 시스템에 쿠버네티스 클러스터를 자동으로 구성해주는 솔루션 사용
   - kubeadm, kops, KRIB, kubespray
   - 4가지 중 kubeadm이 가장 잘 알려져 있다

# 쿠버네티스 구성하기

- 학습을 위해 kubeadm으로 쿠버네티스를 구성
- 쿠버네티스가 설치되는 서버 도느는 가상 머신을 이용해 실제 온프레미스에 가깝게 구성
- 설치되는 과정을 베이그런트로 자동화해 필요하면 쿠버네티스 테스트 환경을 재구성할 수 있도록 함

## Vagrantfile

- 베이그런트 프로비저닝을 위한 정보를 담고 있는 메인 파일
- 명령 프롬프트를 실행하고 Vagrantfile이 있는 경로에서 vagrant up 명령을 입력하면 현재 호스트 내부에 Vagrantfile에 정의된 가상 머신들을 생성하고, 생성한 가상 머신에 쿠버네티스 클러스트를 구성하기 위한 파일들을 호출해 쿠버네티스 클러스터를 자동으로 구성

```bash
# -*- mode: ruby -*-
# vi: set ft=ruby :

Vagrant.configure("2") do |config|
  N = 3  # 쿠버네티스에서 작업을 수행할 워커 노드의 수, 아래 코드의 'args: N'에서 config.sh로 변수를 넘긴다
  Ver = '1.18.4' # 사용하려는 쿠버네티스 버전 설정

  #=============#
  # Master Node #
  #=============#

    config.vm.define "m-k8s" do |cfg|
      cfg.vm.box = "sysnet4admin/CentOS-k8s"
      cfg.vm.provider "virtualbox" do |vb|
        vb.name = "m-k8s(github_SysNet4Admin)"
        vb.cpus = 2
        vb.memory = 3072
        vb.customize ["modifyvm", :id, "--groups", "/k8s-SgMST-1.13.1(github_SysNet4Admin)"]
      end
      cfg.vm.host_name = "m-k8s"
      cfg.vm.network "private_network", ip: "192.168.1.10"
      cfg.vm.network "forwarded_port", guest: 22, host: 60010, auto_correct: true, id: "ssh"
      cfg.vm.synced_folder "../data", "/vagrant", disabled: true

      cfg.vm.provision "shell", path: "config.sh", args: N  # config.sh: kubeadm으로 쿠버네시트를 철치하기 위한 사전 조건을 설정하는 스크립트 파일

			# args: [ Ver, "Main"]: 쿠버네티스 버전 정보(Ver)와 Main이라는 문자를 install_pkg.sh로 넘긴다
      # 두 번재 인자인 Main 문자: intall_pkg.sh에서 조건문으로 처리, 마스터 노드에만 전체 실행 코드를 내려받게 한다
			cfg.vm.provision "shell", path: "install_pkg.sh", args: [ Ver, "Main" ]
      cfg.vm.provision "shell", path: "master_node.sh"  # 마스터 노드 추가
    end

  #==============#
  # Worker Nodes #
  #==============#

  (1..N).each do |i|
    config.vm.define "w#{i}-k8s" do |cfg|
      cfg.vm.box = "sysnet4admin/CentOS-k8s"
      cfg.vm.provider "virtualbox" do |vb|
        vb.name = "w#{i}-k8s(github_SysNet4Admin)"
        vb.cpus = 1
        vb.memory = 2560
        vb.customize ["modifyvm", :id, "--groups", "/k8s-SgMST-1.13.1(github_SysNet4Admin)"]
      end
      cfg.vm.host_name = "w#{i}-k8s"
      cfg.vm.network "private_network", ip: "192.168.1.10#{i}"
      cfg.vm.network "forwarded_port", guest: 22, host: "6010#{i}", auto_correct: true, id: "ssh"
      cfg.vm.synced_folder "../data", "/vagrant", disabled: true
      cfg.vm.provision "shell", path: "config.sh", args: N
      cfg.vm.provision "shell", path: "install_pkg.sh", args: Ver
      cfg.vm.provision "shell", path: "work_nodes.sh"  # 워커 노드 추가
    end
  end

end
```

## config.sh

- kubeadm으로 **쿠버네티스를 설치하기 위한 사전 조건을 설정**하는 스크립트 파일

```bash
#!/usr/bin/env bash

# vi를 호출하면 vim을 호출하도록 프로파일에 입력: 코드에 하이라이트를 넣어 코드를 쉽게 구분이 가능하다
echo 'alias vi=vim' >> /etc/profile

# 쿠버네티스의 설치 요구 조건을 맞추기 위해 스왑되지 않도록 설정한다
swapoff -a
# 시스템이 다시 시작되더라도 스왑되지 않도록 설정
sed -i.bak -r 's/(.+ swap .+)/#\1/' /etc/fstab

# 쿠버네티스를 내려받을 레포지터리를 설정
gg_pkg="packages.cloud.google.com/yum/doc" # 쿠버네티스의 레포지터리 설정을 위한 경로가 너무 길어지지 않도록 경로를 변수로 처리

# 브리지 네트워크를 통과하는 IPv4, IPv6 패킷을 iptables가 관리하도록 설정, 필요에 따라 IPVS(IP Virtual Server) 같은 방식으로도 구성 가능
cat <<EOF > /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64
enabled=1
gpgcheck=0
repo_gpgcheck=0
gpgkey=https://${gg_pkg}/yum-key.gpg https://${gg_pkg}/rpm-package-key.gpg
EOF

# selinux가 제한적으로 사용되지 않도록 permissive 모드로 변경
setenforce 0
sed -i 's/^SELINUX=enforcing$/SELINUX=permissive/' /etc/selinux/config

# RHEL/CentOS 7 have reported traffic issues being routed incorrectly due to iptables bypassed
cat <<EOF >  /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
EOF
modprobe br_netfilter  # br_netfilter를 커널 모듈을 사용해 브리지로 네트워크를 구성, 이때 IP Masquerade를 사용해 내부 네트워크와 외부 네트워크를 분리
# IP 마스커레이드: 커널에서 제공하는 NAT(Network Address Translation) 기능
# br_netfilter를 적용함으로써 아래에서 적용한 iptables가 활성화 된다

# 쿠버네티스 안에서 노드 간 통신을 이름으로 할 수 있도록 각 노드의 호스트 이름과 IP를 /etc/host에 설정
# 워커 노드는 Vagrantfile에서 넘겨받은 N변수로 전달된 노드 수에 맞게 동적으로 생성
echo "192.168.1.10 m-k8s" >> /etc/hosts
for (( i=1; i<=$1; i++  )); do echo "192.168.1.10$i w$i-k8s" >> /etc/hosts; done

# 외부와 통신할 수 있도록 DNS 서버를 지정
cat <<EOF > /etc/resolv.conf
nameserver 1.1.1.1 #cloudflare DNS
nameserver 8.8.8.8 #Google DNS
EOF
```

## install_pkg.sh

- 클러스터 구성을 위해, 가상 머신에 설치되어야 하는 **의존성 패키지**를 명시
- 실습에 필요한 **소스 코드를 특정 가상 머신(m-k8s) 내부에 내려받도록 설정**

```bash
#!/usr/bin/env bash

# 패키지 설치
yum install epel-release -y
yum install vim-enhanced -y
yum install git -y  # 깃허브에서 코드를 내려받을 수 있도록 git을 설치

# 도커 설치 & 구동
yum install docker -y && systemctl enable --now docker

# 쿠버네티스 클러스터 설치, config.sh에서 넘겨받은 변수($1=Ver='1.18.4')로 넘겨받은 버전의 kubectl, kubelet, kubeadm을 설치, kubelet을 시작
yum install kubectl-$1 kubelet-$1 kubeadm-$1 -y
systemctl enable --now kubelet

# _Book_k8sInfra.git 실행 코드를 마스터 노드에만 내려받도록 두 번째 변수($2='Main') 이용
if [ $2 = 'Main' ]; then
  git clone https://github.com/sysnet4admin/_Book_k8sInfra.git  # git 복제
  mv /home/vagrant/_Book_k8sInfra $HOME  # 실습을 진행할 루트 홈디렉터리(/root)로 옮긴다
  find $HOME/_Book_k8sInfra/ -regex ".*\.\(sh\)" -exec chmod 700 {} \;  # 배시 스크립트(.sh)를 find로 찾아서 바로 실행 가능한 상태가 되도록 chmod 700 설정
fi
```

## master_node.sh

- **1개의 가상 머신(m-k8s)을 쿠버네티스 마스터 노드로 구성**하는 스크립트
- 쿠버네티스 클러스터를 구성할 때 꼭 선택해야 하는 **컨테이너 네트워크 인터페이스**도 함께 구성

```bash
#!/usr/bin/env bash

# 쿠버네티스 init: kubeadm을 통해 쿠버네티스의 워커 노드를 받아들일 준비를 한다
kubeadm init --token 123456.1234567890123456 --token-ttl 0 \  # 토큰을 '123456.1234567890123456'으로 지정, ttl(time to live)을 0으로 설정 => 기본값인 24시간 후에 토큰이 계속 유지되도록 함 & 워커 노드가 정해진 토큰으로 들어오게 한다
--pod-network-cidr=172.16.0.0/16 --apiserver-advertise-address=192.168.1.10   # 쿠버네티스가 자동으로 컨테이너에 부여하는 네트워크를 172.16.0.0/16으로 제공, 워커 노드가 접속하는 API 서버의 IP를 192.168.1.10로 지정: 워커 노드들이 자동으로 API 서버에 연결되게 한다

# master 노드에서 현재 사용자가 쿠버네티스를 정상적으로 구동할 수 있게 설정 파일을 /root 파일에 복사, 쿠버네티스를 이용할 사용자에게 권한을 설정
mkdir -p $HOME/.kube
cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
chown $(id -u):$(id -g) $HOME/.kube/config

# 쿠버네티스 네트워크를 구성: 컨테이너 네트워크 인터페이스(CNI)인 캘리코의 설정 적용
kubectl apply -f \
https://raw.githubusercontent.com/sysnet4admin/IaC/master/manifests/172.16_net_calico.yaml
```

## work_nodes.sh

- **3대의 가상 머신(w1-k8s, w2-k8s, w3-k8s)에 쿠버네티스 워커 노드를 구성**하는 스크립트
- 마스터 노드에 구성된 클러스터에 조인이 필요한 정보를 모두 코드화 ⇒ 스크립트를 실행하기만 하면 편하게 워커 노드로서 쿠버네티스 클러스터에 조인

```bash
#!/usr/bin/env bash

# kubeadm을 이용해 쿠버네티스 마스터 노드에 접속
kubeadm join --token 123456.1234567890123456 \  # 연결에 필요한 토큰 사용
             --discovery-token-unsafe-skip-ca-verification 192.168.1.10:6443
						# 간단하게 구성하기 위해 인증을 무시(--discovery-token-unsafe-skip-ca-verification)
						# API 서버 주소로 기본 포트 번호인 6443번 포트에 접속하도록 설정
```

## 생성된 노드 확인

```bash
vagrant up

# m-k8s에서 수행
kubectl get nodes
```

## 파드 배포 중심으로 쿠버네티스 구성 요소 살펴보기

```bash
# m-k8s에서 수행
kubectl get pods --all-namespaces  # --all-namespaces: 기본 네임스페이스인 default 외에 모든 것을 표시
```

## 관리자/개발자가 파드를 배포할 때

### 마스터 노드

1. kubectl : 쿠버네티스 클러스터에 명령을 내리는 역할, 마스터 노드에 위치해야만 하는 것은 아님
2. API 서버 : 쿠버네티스 클러스터의 중심 역할을 하는 통로. 주로 상태값을 저장하는 etcd와 통신하지만, 그 밖의 요소들 또한 API 서버를 중심에 두고 통신하므로 역할이 매우 중요
3. etcd : 구성 요소들의 상태 값이 모두 저장되는 곳. etcd 정보만 백업되어 있다면 긴급한 장애 상황에서도 쿠버네티스 클러스터 복구가 가능. etcd는 분산 저장이 가능한 key-value 저장소이므로 복제 해서 여러 곳에 저장해두면 하나의 etcd에서 장애가 나더라도 가용성을 확보할 수 있다
4. 컨트롤러 매니저 : 쿠버네티스 클러스터의 오브젝트 상태를 관리. 워커 노트에서 통신이 되지 않는 경우, 상태 체크와 복구는 컨트롤러 매니저에 속한 노트 컨트롤러에서 이뤄진다. 레플리카셋 컨트롤러는 레플리카셋에 요청받은 파드 개수대로 파드를 생성. 엔드 포인트 컨트롤러 …
5. 스케줄러 : 노드의 상태와 자원, 레이블, 요구 조건 등을 고려해 파드를 어떤 워커 노트에 생성할 것인지 결정하고 할당

### 워커 노드

1. kubelet : 파드의 구성 내용을 받아서 컨테이너 런타임으로 전달하고, 파드 안의 컨테이너들이 정상적으로 작동하는지 모니터링
2. 컨테이너 런타임(CRI) : 파드를 이루는 컨테이너의 실행을 담당. 파드 안에서 다양한 종류의 컨테이너가 문제 없이 작동하게 만드는 표준 인터페이스
3. 파드 : 한 개 이상의 컨테이너로 단일 목적의 일을 하기 위해서 모인 단위. 파드는 언제라도 죽을 수 있는 존재다

### 선택 가능 구성요소 (구분을 위해 11번 부터 진행)

1. 네트워크 플러그인 : 쿠버네티스 클러스터의 통신을 위해서 네트워크 플러그인을 선택하고 구성해야 함. 네트워크 플러그인은 일반적으로 CNI로 구성. 책에서는 캘리코를 선택해 구성
2. CoreDNS : 클라우드 네이티브 컴퓨팅 재단에서 보증하는 프로젝트, 빠르고 유연한 DNS 서버

## 사용자가 배포된 파드에 접속할 때

1. kube-proxy : 쿠버네티스 클러스터는 파드가 위치한 노드에 kube-proxy를 통해 파드가 통신할 수 있는 네트웤르르 설정. 실제 통신은 br_netfilter와 iptables로 관리
2. 파드 : 이미 배포된 파드에 접속하고 필요한 내용을 전달받는다. 이때 대부분 사용자는 파드가 어느 워커 노드에 위치하는지 신경 쓰지 않아도 된다

## 파드의 생명주기로 쿠버네티스 구성 요소 살펴보기

- 쿠버네티스의 가장 큰 장점은 쿠버네티스의 구성 요소마다 하는 일이 명확하게 구분되어 각자의 역할만 충실하게 수행하면 시스템이 안정적으로 운영됨
- 역할이 나뉘어 있어서 문제가 발생했을 때 어느 부분에서 문제가 발생했는지 디버깅하기 쉽다
- 생명주기
  1. kubectl을 통해 API 서버에 파드 생성을 요청
  2. (업데이트 발생 시 매번) API 서버에 전달된 내용이 있으면 API 서버는 etcd에 전달된 내용을 모두 기록하고, 클러스터의 상태 값을 최신으로 유지

     ⇒ 각 요소가 상태를 업데이트할 때마다 모두 API 서버를 통해 etcd에 기록

  3. API 서버에 파드 생성이 요청된 것을 컨트롤러 매니저가 인지

     ⇒ 컨트롤러 매니저는 파드를 생성하고, 이 상태를 API 서버에 전달

  4. API 서버에 파드가 생성되었다는 정보를 스케줄러가 인지

     ⇒ 스케줄러는 생성된 파드를 어떤 워커 노드에 적용할지 조건을 고려해 결정하고 해당 워커 노드에 파드를 띄우도록 요청

  5. API 서버에 전달된 정보대로 지정한 워커 노드에 파드가 속해있는지 스케줄러가 kubelet으로 확인
  6. kubelet에서 컨테이너 터란임으로 파드 생성을 요청
  7. 파드가 생성
  8. 파드가 사용 가능한 상태가 된다
- 쿠버네티스는 작업을 순서대로 진행하는 워크플로 구조가 아니라 선언적인 시스템 구조를 가지고 있다
  ⇒ 각 요소가 추구하는 상태를 선언하면, 현재 상태와 맞지 않는지 점검하고, 그것에 맞추도록 노력하는 구조를 뜻한다

## 쿠버네티스 구성 요소의 기능 검증하기

### kubectl

- 마스터 노드에 위치할 필요는 없다

```bash
# 1. 수퍼 푸티 세션창에서 w3-k8s를 더블클릭해 터미널에 접속

# 2. 노드 조회를 실행
kubectl get nodes
# 쿠버네티스 클러스터의 정보를 kubectl 알지 못하기 때문에 노드 정보를 표시하지 못함
# kubectl은 API 서버를 통해 쿠버네티스에 명령을 내린다. ]
# 따라서, kubectl이 어디에 있더라도 API 서버의 접속정보만 있다면 어느 곳에서든 쿠버네티스 클러스터에 명령을 내릴 수 있다

# 3. 쿠버네티스 클러스터의 정보를 마스터 노드에서 scp(secure copy) 명령으로 w3-k8s의 현재 디렉터리(.)에 받아온다
scp rot@192.168.1.10:/etc/kubernetes/admin.conf .
yes  # 접속 기록이 없기 때문에 known_hosts로 저장하도록 yes를 입력
vagrant  # 마스터 노드 접속 암호인 vagrant도 입력

# 4. 쿠버네티스 클러스터 정보를 입력받는 옵션(--kubeconfig)와 마스터 노드에서 받아온 admin.conf를 실행
kubectl get nodes --kubeconfig admin.conf
```

### **kubelet**

- 쿠버네티스에서 파드의 생성과 상태 관리 및 복구 등을 담당하는 중요한 구성요소
- kubelet에 문제가 생기면 파드가 정상적으로 관리되지 않는다

```bash
# 1. 기능을 검증하기 위해 실제로 파드를 배포
kubecte create -f ~/{경로}/nginx-pod.yaml
# nginx 웹 서버 파드를 배포, -f: filename을 의미

# 2. 파드가 정상적으로 배포된 상태인지 확인
kubectl get pod

# 3. 파드가 배포된 워커 노드를 확인
kubectl get pods -o wide
# -o: output의 약어로 출력을 특정 형식으로 해주는 옵션, wide: 출력 정보를 더 많이 표시해주는 옵션

# 4. 배포된 노드인 w2-k8s에 접속해 kublet 서비스를 멈춘다
systemctl stop kubelet

# 5. m-k8s에서 상태를 확인하고, 파드를 삭제
kubectl get pod
kubectl delete pod nginx-pod

# 6. 수퍼푸티 명령 창에 변화가 없다면, ctrl+c를 눌어 명령을 중지

# 7. 파드의 상태를 확인
kubectl get pod
# Terminating 상태지만, kubelet이 작동하지 않아 파드는 삭제되지 않음

# 8. w2-k8s에서 kubelet을 복구
systemctl start kubelet

# 9. nginx 파드가 삭제됬는지 확잉ㄴ
kubcetl get pod
```

⇒ kubelet에 문제가 생기면 파드가 제대로 관리되지 않음을 확인할 수 있다

### kube-proxy

- kubelet이 파드의 상태를 관리한다면, kube-proxy는 파드의 통신을 담당
- 앞서 config.sh에서 br_netfilter 커널 모듈을 적재하고 iptables를 거쳐 통신하도록 설정했다
- 설정이 정상적이지 않을 경우를 아래에서 테스트 실습 진행

```bash
# 1. 테스트 진행을 위해 마스터 노드인 m-k8s에서 다시 파드를 배포
kubectl create -f ~/{경로}/nginx.yaml

# 2. 파드의 IP와 워커 노드를 확인
kubectl get pods -o wide

# 3. curl(client URL)로 파드의 전 단계에서 확인한 IP로 nginx 웹 서버 메인 페이지 내용을 확인
curl 172.16.103.130

# 4. w2-k8s에 접속, 파드가 위치한 워커 노드에서 br_netfiletr 모듈을 제거하고 다시 실행
modprobe -r br_netfilter
systemctel restart network
# -r: remove를 의미

# 5. curl로 파드의 nginx 웹 서버 페이지 정보를 받아온다. 파드에서 정보를 받아오지 못했다면 요청을 종료
curl 172.16.103.130

# 6. 파드의 상태를 확인
kubectl get pod -o wide

# 7. 정상적으로 nginx 웹 서버 페이지 정보를 받아올 수 있는 상태로 만들어보자
modprobe br_netfilter  # br_netfilter를 커널에 적재
reboot  # 시스템 다시 시작

# 8. (일정 시간 후)m-k8s 파드의 상태 확인
kubectl get pod -o wide
# RESTARTS가 1로 증가하고, IP가 변경된 것을 확인 가능

# 9. 바뀐 IP로 curl 명령을 실행해 파드로부터 정보를 정상적으로 받아오는지 확인
curl 172.16.103.131

# 10. 다음 실습을 위해 배포한 파드를 삭제
kubectl delete -f ~/{경로}/nginx-pod.yaml
```

# 쿠버네티스 기본 사용법 배우기

### 파드 생성

```bash
kubectl run nginx-pod --image=nginx
# kubectl run {파드 이름} {생성 이미지 이름}
```

- kubectl run 명령어를 통해 쉽게 파드를 생성 가능
- kubectl create 방식으로 파드를 생성하는 것과 비교
  - create로 파드를 생성하려면 kubectl create에 deployment를 추가해서 실행해야 한다
  - run으로 파드를 생성하면 단일 파드 1개만 생성되고 관리
  - create deployment로 파드를 생성하면 디플로이먼트라는 관리 그룹 내에서 파드가 생성
  - 최근에는 대부분 create를 이용하는 방식을 사용하는 편
